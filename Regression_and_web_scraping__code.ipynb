{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " Regression_and_web_scraping _code.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NadAAaHH/SDAIA-T5-NBM_Project/blob/main/Regression_and_web_scraping__code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8YbRvGBsNIF"
      },
      "source": [
        "**Step1:** Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjTmZyFBsMav",
        "outputId": "e2b48070-5a65-44aa-da36-9d18d2a8de52"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import time, os\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from fake_useragent import UserAgent"
      ],
      "execution_count": null,
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'fake_useragent'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-1-23ccff21b5e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mselenium\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwebdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKeys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mselenium\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwebdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchrome\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mfake_useragent\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mUserAgent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'fake_useragent'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSGjPb8MsXJw"
      },
      "source": [
        "**Step2:** scrabing LinkedIn to get the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fw-qFoDP6ADd"
      },
      "source": [
        "chromedriver = r\"C:\\Users\\Nadar\\Downloads\\chromedriver_win32\\chromedriver\" # path to the chromedriver executable\n",
        "os.environ[\"webdriver.chrome.driver\"] = chromedriver"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UW5ZIfqc6ADe"
      },
      "source": [
        "url = \"https://www.linkedin.com/login?\"\n",
        "driver = webdriver.Chrome(chromedriver)\n",
        "driver.get(url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oz8zAFQX6ADf"
      },
      "source": [
        "username_box = driver.find_element_by_xpath('/html/body/div/main/div[2]/div[1]/form/div[1]/input')\n",
        "username_box.send_keys(\"username\")\n",
        "\n",
        "password_box = driver.find_element_by_xpath('/html/body/div/main/div[2]/div[1]/form/div[2]/input')\n",
        "password_box.send_keys(\"password\")\n",
        "\n",
        "# hit enter\n",
        "enter_btn = driver.find_element_by_xpath('/html/body/div/main/div[2]/div[1]/form/div[3]/button')\n",
        "enter_btn.click()\n",
        "\n",
        "time.sleep(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1aPuoII6ADf"
      },
      "source": [
        "profile_url = \"https://linkedin.com/in/dmitry-denisov-022102103\"\n",
        "driver.get(profile_url);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vF1AGO5z6ADg",
        "outputId": "c588cd24-bdc0-4b5c-f9a4-bec8cde27e74"
      },
      "source": [
        "# to get the number of connections\n",
        "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
        "print(soup.find('span', class_='t-bold').text)\n",
        "\n",
        "# to get the number of followers\n",
        "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
        "print(soup.find('span', class_='align-self-center t-14 t-black--light').text.split()[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "490\n",
            "498\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Igd255O6ADg"
      },
      "source": [
        "post_url = \"/detail/recent-activity/shares/\"\n",
        "\n",
        "get_posts = profile_url + post_url.replace(' ', '+')\n",
        "driver.get(get_posts);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XohbQZnU6ADg",
        "outputId": "26355506-de38-4559-a34f-2f20fb1ac4ae"
      },
      "source": [
        "# to get the number of likes of posts (without scrolling)\n",
        "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
        "\n",
        "lst_reactions = [i.text for i in soup.find_all('span', class_='v-align-middle social-details-social-counts__reactions-count')]\n",
        "print(lst_reactions)\n",
        "\n",
        "# to get how old a post is (without scrolling)\n",
        "lst_howold = []\n",
        "for tag in soup.find_all('span', class_='feed-shared-actor__sub-description t-12 t-normal t-black--light'):\n",
        "    for i in tag.find_all('span', class_=\"visually-hidden\"):\n",
        "        lst_howold.append(i.text)\n",
        "print(lst_howold)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['19', '23', '33', '26', '9', '1']\n",
            "['3 days ago', '9 months ago', '1 year ago', '1 year ago', '1 year ago', '1 year ago', '1 year ago', '1 year ago']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AxV2AHS6ADh"
      },
      "source": [
        "for i in range(5):\n",
        "    #Scroll\n",
        "    driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
        "    \n",
        "    #Wait for page to load\n",
        "    time.sleep(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbc6uOPw6ADi",
        "outputId": "589fff8f-5d75-417e-ac5a-83260444f7af"
      },
      "source": [
        "# to get the total number of posts\n",
        "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
        "print(len(soup.find_all('div', class_='occludable-update ember-view')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12\n"
          ]
        }
      ]
    }
  ]
}